# Predicci√≥n del Rendimiento Azucarero mediante Machine Learning

## üìã Descripci√≥n del Proyecto

Este proyecto implementa modelos de **regresi√≥n** y **clasificaci√≥n** para predecir y categorizar el rendimiento de cultivos de ca√±a de az√∫car en el Ingenio Providencia. El objetivo es proporcionar herramientas anal√≠ticas que permitan tomar decisiones m√°s informadas sobre la planificaci√≥n y manejo de cultivos.

## üéØ Objetivos

### Parte 1: Modelos de Regresi√≥n
Predecir dos variables clave de rendimiento:
- **TCH (Toneladas de Ca√±a por Hect√°rea)**: Indicador de productividad de la tierra
- **%Sac.Ca√±a (Porcentaje de Sacarosa)**: Medida de calidad de la ca√±a y cantidad de az√∫car extra√≠ble

### Parte 2: Modelos de Clasificaci√≥n
Categorizar los registros en tres niveles de desempe√±o (Alto, Medio, Bajo) para:
- **TCH**: Niveles de productividad
- **%Sac.Ca√±a**: Niveles de sacarosa

## üìä Datasets Utilizados

- **HISTORICO_SUERTES.xlsx**: Datos hist√≥ricos para modelos de regresi√≥n
- **BD_IPSA_1940.xlsx**: Datos para modelos de clasificaci√≥n

## üî¨ Metodolog√≠a

### Parte 1: An√°lisis de Regresi√≥n

#### 1. An√°lisis Exploratorio de Datos (EDA)
- Exploraci√≥n inicial del dataset (shape, tipos de datos, valores faltantes)
- Detecci√≥n de outliers y valores at√≠picos
- Visualizaci√≥n de distribuciones mediante histogramas
- An√°lisis de correlaciones entre variables

#### 2. Limpieza y Preprocesamiento
- **Eliminaci√≥n de columnas con >50% de valores nulos**
- **Manejo de data leakage**: Eliminaci√≥n de variables que representan resultados futuros:
  - Variables post-cosecha: `TCHM`, `TAH`, `TAHM`, `KATRHM`
  - Variables ambiguas: `Producto`, `%Sac.Ca√±a`, `%Sac.Muestreadora`, `%ATR`, `%Fibra Ca√±a`, `%AR Jugo`, `%ME Min`, `%ME Veg`, `%ME Tot`
  - Variables descriptivas: `Nombre`, `Suerte`, `Hacienda`
- **Encoding de variables categ√≥ricas** mediante One-Hot Encoding
- **Imputaci√≥n de valores faltantes** en variables num√©ricas

#### 3. Desarrollo de Modelos
- Implementaci√≥n de **Regresi√≥n Lineal Multiple**
- An√°lisis de significancia estad√≠stica de variables
- Evaluaci√≥n de supuestos del modelo:
  - Linealidad
  - Homocedasticidad
  - Normalidad de errores
  - Multicolinealidad (VIF)

#### 4. Validaci√≥n y Evaluaci√≥n
- Divisi√≥n de datos en entrenamiento y prueba (holdout)
- M√©tricas calculadas:
  - **R¬≤** (Coeficiente de determinaci√≥n)
  - **RMSE** (Root Mean Squared Error)
  - **MAE** (Mean Absolute Error)
- An√°lisis de residuales

### Parte 2: An√°lisis de Clasificaci√≥n

#### 1. Creaci√≥n de Categor√≠as
Se definieron umbrales mediante **cuantiles (terciles)**:

**Para TCH:**
- Bajo: ‚â§ Percentil 33
- Medio: > Percentil 33 y ‚â§ Percentil 66
- Alto: > Percentil 66

**Para %Sac.Ca√±a:**
- Bajo: ‚â§ Percentil 33
- Medio: > Percentil 33 y ‚â§ Percentil 66
- Alto: > Percentil 66

**Justificaci√≥n**: Los cuantiles garantizan una distribuci√≥n equilibrada de las clases y capturan la variabilidad natural de los datos sin requerir conocimiento de dominio espec√≠fico.

#### 2. Desarrollo de Modelos
- **Regresi√≥n Log√≠stica** con regularizaci√≥n
- **K-Nearest Neighbors (KNN)**
- An√°lisis de significancia estad√≠stica mediante:
  - Prueba de Wald
  - Valores p (nivel de significancia Œ± = 0.05)
- Identificaci√≥n de multicolinealidad entre variables (edad, semsmad, vejez)

#### 3. Validaci√≥n y Evaluaci√≥n
- **Validaci√≥n cruzada** (k-fold cross-validation)
- M√©tricas de clasificaci√≥n:
  - **Accuracy** (Exactitud general)
  - **Precision** (Precisi√≥n por clase)
  - **Recall** (Sensibilidad)
  - **F1-Score** (Media arm√≥nica de Precision y Recall)
  - **Kappa de Cohen**
- Matrices de confusi√≥n para an√°lisis detallado

## üõ†Ô∏è Tecnolog√≠as Utilizadas

```python
# Librer√≠as principales
- pandas              # Manipulaci√≥n de datos
- numpy               # Operaciones num√©ricas
- matplotlib          # Visualizaci√≥n
- seaborn             # Visualizaci√≥n estad√≠stica
- scikit-learn        # Modelos de ML
- statsmodels         # An√°lisis estad√≠stico
```

## üìà Resultados Principales

### Modelos de Regresi√≥n
- Identificaci√≥n de variables m√°s significativas para predecir TCH y %Sac.Ca√±a
- Evaluaci√≥n del poder predictivo mediante m√©tricas R¬≤, RMSE y MAE
- Detecci√≥n y manejo de multicolinealidad

### Modelos de Clasificaci√≥n
- Categorizaci√≥n efectiva en tres niveles de desempe√±o
- Variables significativas (p ‚â§ 0.05): `semsmad`, `edad`, `cortes`, `vejez`
- Comparaci√≥n de rendimiento entre Regresi√≥n Log√≠stica y KNN
- An√°lisis de importancia de caracter√≠sticas

## üìÅ Estructura del Repositorio

```
Lab1Repo/
‚îú‚îÄ‚îÄ Consigna.md                              # Descripci√≥n del laboratorio
‚îú‚îÄ‚îÄ Parte1_Lab_1_APO_III-TERMINADO.ipynb    # An√°lisis de regresi√≥n
‚îú‚îÄ‚îÄ Lab1_Parte2_final.ipynb                 # An√°lisis de clasificaci√≥n
‚îú‚îÄ‚îÄ README.md                               # Este archivo
‚îî‚îÄ‚îÄ HISTORICO_SUERTES.xlsx                  # Dataset (no incluido en repo p√∫blico)
‚îî‚îÄ‚îÄ BD_IPSA_1940.xlsx                       # Dataset (no incluido en repo p√∫blico)
```

## üîë Hallazgos Clave

1. **Data Leakage Prevention**: Se identificaron y eliminaron variables que representaban informaci√≥n futura o resultados post-cosecha, evitando sobreajuste artificial

2. **Multicolinealidad**: Se detect√≥ alta correlaci√≥n entre `edad`, `semsmad` y `vejez`, requiriendo t√©cnicas de regularizaci√≥n

3. **Variables Significativas**: 
   - Para TCH: edad del cultivo, n√∫mero de cortes, condiciones clim√°ticas
   - Para clasificaci√≥n: semsmad, cortes, vejez mostraron significancia estad√≠stica

4. **Balance de Clases**: El uso de terciles garantiz√≥ distribuciones equilibradas en las categor√≠as

## üë• Autores

**Equipo de Desarrollo**
- Juan Pablo Parra Bernal

**Curso**: APO III - S√©ptimo Semestre  
**Instituci√≥n**: [Tu Universidad]  
**Fecha**: Diciembre 2025

## üìù Notas

- Los datasets no est√°n incluidos en el repositorio p√∫blico por pol√≠ticas de privacidad
- El c√≥digo est√° completamente documentado en los notebooks Jupyter
- Se siguieron buenas pr√°cticas de ciencia de datos y machine learning

## üöÄ C√≥mo Usar

1. Clonar el repositorio
```bash
git clone https://github.com/Juanpapb0401/Prediccion-Rendimiento-Azucar-ML.git
```

2. Instalar dependencias
```bash
pip install pandas numpy matplotlib seaborn scikit-learn statsmodels openpyxl
```

3. Abrir los notebooks Jupyter
```bash
jupyter notebook Parte1_Lab_1_APO_III-TERMINADO.ipynb
jupyter notebook Lab1_Parte2_final.ipynb
```

## üìä Visualizaciones Incluidas

- Histogramas de distribuci√≥n de variables
- Matrices de correlaci√≥n
- Gr√°ficos de dispersi√≥n
- An√°lisis de residuales
- Matrices de confusi√≥n
- Importancia de caracter√≠sticas

## üéì Conceptos Aplicados

- Regresi√≥n Lineal M√∫ltiple
- Regresi√≥n Log√≠stica
- K-Nearest Neighbors
- Validaci√≥n Cruzada
- Regularizaci√≥n
- An√°lisis de Multicolinealidad (VIF)
- Pruebas de Hip√≥tesis
- Ingenier√≠a de Caracter√≠sticas
- Manejo de Datos Faltantes

## üìã Resumen de la Consigna

El laboratorio consisti√≥ en desarrollar modelos predictivos para el Ingenio Providencia con dos objetivos principales:

### 1. Regresi√≥n (HISTORICO_SUERTES.xlsx)
Predecir:
- **Toneladas de ca√±a por hect√°rea (TCH)**: Productividad de la tierra
- **Porcentaje de sacarosa (%Sac.Ca√±a)**: Calidad de la ca√±a

### 2. Clasificaci√≥n (BD_IPSA_1940.xlsx)
Crear categor√≠as de desempe√±o (Alto, Medio, Bajo) para TCH y %Sac.Ca√±a

### Criterios de Evaluaci√≥n:
- ‚úÖ Claridad y rigor en el an√°lisis exploratorio
- ‚úÖ Correcta implementaci√≥n de modelos de regresi√≥n y clasificaci√≥n
- ‚úÖ Validaci√≥n adecuada y uso de m√©tricas apropiadas
- ‚úÖ Comunicaci√≥n clara de resultados
- ‚úÖ Propuestas de mejora e innovaci√≥n

## üí° C√≥mo lo Solucion√©

### Enfoque de Regresi√≥n (Parte 1):
1. **EDA Exhaustivo**: An√°lisis profundo de distribuciones, correlaciones y valores faltantes
2. **Preprocesamiento Riguroso**: 
   - Elimin√© columnas con >50% de valores nulos
   - Identifiqu√© y elimin√© variables de "data leakage" (TCHM, TAH, variables post-cosecha)
   - Apliqu√© One-Hot Encoding a variables categ√≥ricas
3. **Modelado**: Regresi√≥n lineal m√∫ltiple con validaci√≥n de supuestos
4. **Evaluaci√≥n**: M√©tricas R¬≤, RMSE, MAE y an√°lisis de residuales

### Enfoque de Clasificaci√≥n (Parte 2):
1. **Categorizaci√≥n Inteligente**: Uso de terciles para garantizar balance de clases
2. **An√°lisis Estad√≠stico**: Prueba de Wald y valores p para identificar variables significativas
3. **Modelos Comparativos**: Regresi√≥n Log√≠stica vs KNN
4. **Validaci√≥n Robusta**: Validaci√≥n cruzada y m√∫ltiples m√©tricas (Accuracy, Precision, Recall, F1, Kappa)

### Decisiones Clave:
- **Prevenci√≥n de Data Leakage**: Eliminaci√≥n de variables futuras como `Producto`, `%Sac.Ca√±a`, `%Sac.Muestreadora`
- **Manejo de Multicolinealidad**: Identificaci√≥n de correlaci√≥n entre edad, semsmad y vejez
- **Terciles para Categorizaci√≥n**: Decisi√≥n fundamentada en distribuci√≥n equilibrada de datos
- **Variables Significativas**: Selecci√≥n basada en valores p (Œ± = 0.05)

---

**Nota**: Este proyecto fue desarrollado con fines acad√©micos como parte del Laboratorio 1 del curso APO III.
